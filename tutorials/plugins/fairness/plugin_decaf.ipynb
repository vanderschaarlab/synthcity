{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# synthcity absolute\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "log.remove()\n",
    "log.add(sink=sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "eval_plugin = \"decaf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27415a",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# third party\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# It will apply a perturbation at each node provided in perturb.\n",
    "def gen_data_nonlinear(\n",
    "    G: Any,\n",
    "    base_mean: float = 0,\n",
    "    base_var: float = 0.3,\n",
    "    mean: float = 0,\n",
    "    var: float = 1,\n",
    "    SIZE: int = 10000,\n",
    "    err_type: str = \"normal\",\n",
    "    perturb: list = [],\n",
    "    sigmoid: bool = True,\n",
    "    expon: float = 1.1,\n",
    ") -> pd.DataFrame:\n",
    "    list_edges = G.edges()\n",
    "    list_vertex = G.nodes()\n",
    "\n",
    "    order = []\n",
    "    for ts in nx.algorithms.dag.topological_sort(G):\n",
    "        order.append(ts)\n",
    "\n",
    "    g = []\n",
    "    for v in list_vertex:\n",
    "        if v in perturb:\n",
    "            g.append(np.random.normal(mean, var, SIZE))\n",
    "            print(\"perturbing \", v, \"with mean var = \", mean, var)\n",
    "        else:\n",
    "            if err_type == \"gumbel\":\n",
    "                g.append(np.random.gumbel(base_mean, base_var, SIZE))\n",
    "            else:\n",
    "                g.append(np.random.normal(base_mean, base_var, SIZE))\n",
    "\n",
    "    for o in order:\n",
    "        for edge in list_edges:\n",
    "            if o == edge[1]:  # if there is an edge into this node\n",
    "                if sigmoid:\n",
    "                    g[edge[1]] += 1 / 1 + np.exp(-g[edge[0]])\n",
    "                else:\n",
    "                    g[edge[1]] += g[edge[0]] ** 2\n",
    "    g = np.swapaxes(g, 0, 1)\n",
    "\n",
    "    return pd.DataFrame(g, columns=list(map(str, list_vertex)))\n",
    "\n",
    "\n",
    "def generate_synth(size: int = 100) -> Tuple[pd.DataFrame, list, dict]:\n",
    "    # causal structure is in dag_seed\n",
    "    dag_seed = [\n",
    "        [1, 2],\n",
    "        [1, 3],\n",
    "        [1, 4],\n",
    "        [2, 5],\n",
    "        [2, 0],\n",
    "        [3, 0],\n",
    "        [3, 6],\n",
    "        [3, 7],\n",
    "        [6, 9],\n",
    "        [0, 8],\n",
    "        [0, 9],\n",
    "    ]\n",
    "    # edge removal dictionary\n",
    "    bias_dict = {6: [3]}  # This removes the edge into 6 from 3.\n",
    "\n",
    "    # DATA SETUP according to dag_seed\n",
    "    G = nx.DiGraph(dag_seed)\n",
    "    data = gen_data_nonlinear(G, SIZE=size)\n",
    "    return data, dag_seed, bias_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a704d",
   "metadata": {},
   "source": [
    "## Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f72b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dag, bias = generate_synth(1000)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209df8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Plugins().get(eval_plugin, n_iter=200)\n",
    "\n",
    "model.fit(data, dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2050ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(10, biased_edges=bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6eb46",
   "metadata": {},
   "source": [
    "## Synthetic dataset - with DAG learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024068f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _, _ = generate_synth(200)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Plugins().get(\n",
    "    eval_plugin,\n",
    "    n_iter=200,\n",
    "    struct_learning_enabled=True,\n",
    "    #struct_learning_search_method=\"d-struct\",\n",
    "    batch_size=100,\n",
    ")\n",
    "\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2853186",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
