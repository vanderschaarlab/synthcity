{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 9: Dealing with missing data\n",
    "\n",
    "Synthcity does not handle missing data on it's own. It assumes that you have imputed any missing values yourself first. So, in this tutorial, we will learn how to do this with another of the van der Schaar Lab's modules, `HyperImpute`. We will then show that we can happily generate a synthetic data afterwards."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start you will need to install the library hyperimpute. This can be done with the command `pip install hyperimpute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install synthcity\n",
    "!pip install hyperimpute\n",
    "!pip uninstall -y torchaudio torchdata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from hyperimpute.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "We will use the diabetes dataset from SKLearn, but we need to introduce some NaN values in order to simulate the missingness that we will then fix with HyperImpute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load baseline dataset\n",
    "X, y = load_diabetes(as_frame=True, return_X_y=True)\n",
    "df_ = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Simulate missing data\n",
    "percentage_missing = 0.2\n",
    "mechanism = \"MCAR\"\n",
    "x_miss = simulate_nan(np.asarray(df_), percentage_missing, mechanism)[\"X_incomp\"]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(x_miss, columns = df_.columns)\n",
    "print(\"The diabetes dataset with 20% missing values.\\n\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericDataLoader(\n",
    "    df,\n",
    "    target_column=\"target\",\n",
    "    sensitive_columns=[\"sex\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "syn_model = Plugins().get(\"ctgan\")\n",
    "\n",
    "syn_model.fit(loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! Here we see that Synthcity cannot handle NaN values. Proof that we need to impute first!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Impute\n",
    "First we can view the different possible Imputation plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperimpute.plugins.imputers import Imputers, ImputerPlugin\n",
    "\n",
    "imputers = Imputers()\n",
    "imputers.list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an imputer\n",
    "Imputers are loaded with `Imputers().get(method_name)`. Below we explain all the parameters we are using as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputers().get(\n",
    "    \"hyperimpute\",  # the name of the imputation method.\n",
    "    # The rest of the kwargs are specific to the method\n",
    "    # optimizer: str. The optimizer to use: simple, hyperband, bayesian\n",
    "    optimizer=\"hyperband\",\n",
    "    # classifier_seed: list. Model search pool for categorical columns.\n",
    "    classifier_seed=[\"logistic_regression\", \"catboost\", \"xgboost\", \"random_forest\"],\n",
    "    # regression_seed: list. Model search pool for continuous columns.\n",
    "    regression_seed=[\n",
    "        \"linear_regression\",\n",
    "        \"catboost_regressor\",\n",
    "        \"xgboost_regressor\",\n",
    "        \"random_forest_regressor\",\n",
    "    ],\n",
    "    # class_threshold: int. how many max unique items must be in the column to be is associated with categorical\n",
    "    class_threshold=5,\n",
    "    # imputation_order: int. 0 - ascending, 1 - descending, 2 - random\n",
    "    imputation_order=2,\n",
    "    # n_inner_iter: int. number of imputation iterations\n",
    "    n_inner_iter=10,\n",
    "    # select_model_by_column: bool. If true, select a different model for each column. Else, it reuses the model chosen for the first column.\n",
    "    select_model_by_column=True,\n",
    "    # select_model_by_iteration: bool. If true, selects new models for each iteration. Else, it reuses the models chosen in the first iteration.\n",
    "    select_model_by_iteration=True,\n",
    "    # select_lazy: bool. If false, starts the optimizer on every column unless other restrictions apply. Else, if for the current iteration there is a trend(at least to columns of the same type got the same model from the optimizer), it reuses the same model class for all the columns without starting the optimizer.\n",
    "    select_lazy=True,\n",
    "    # select_patience: int. How many iterations without objective function improvement to wait.\n",
    "    select_patience=5,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute the missing values\n",
    "We impute the missing values with `imputer.fit_transform()`, which is a style you may be familiar with from library `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_imputed = imputer.fit_transform(df.copy())\n",
    "display(x_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericDataLoader(\n",
    "    x_imputed,\n",
    "    target_column=\"target\",\n",
    "    sensitive_columns=[\"sex\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "syn_model = Plugins().get(\"ctgan\")\n",
    "\n",
    "syn_model.fit(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_syn = syn_model.generate(count=df_.shape[0]).dataframe()\n",
    "display(X_syn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "syn_model.plot(plt, loader, plots=[\"tsne\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!\n",
    "We have now generated synthetic data with synthcity starting from a dataset with missing values thanks to [HyperImpute](https://github.com/vanderschaarlab/hyperimpute). Visit the (HyperImpute tutorials)[https://github.com/vanderschaarlab/hyperimpute/tree/main/tutorials] for more details on how to impute data using the various different methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement towards Machine learning and AI for medicine, you can do so in the following ways!\n",
    "\n",
    "### Star [Synthcity](https://github.com/vanderschaarlab/synthcity) on GitHub\n",
    "\n",
    "- The easiest way to help our community is just by starring the Repos! This helps raise awareness of the tools we're building.\n",
    "\n",
    "\n",
    "### Checkout other projects from vanderschaarlab\n",
    "- [HyperImpute](https://github.com/vanderschaarlab/hyperimpute) - the module you have just learnt to use for synthcity!\n",
    "- [AutoPrognosis](https://github.com/vanderschaarlab/autoprognosis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthcity-all2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
