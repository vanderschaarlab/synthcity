{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51cc4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from synthcity.utils.serialization import save_to_file, load_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285838f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/code/datasets/ward\")\n",
    "\n",
    "train_static = pd.read_csv(base_path / \"ward_static_train_data.csv.gz\")\n",
    "train_temporal = pd.read_csv(base_path / \"ward_temporal_train_data_eav.csv.gz\")\n",
    "\n",
    "test_static = pd.read_csv(base_path / \"ward_static_test_data.csv.gz\")\n",
    "test_temporal = pd.read_csv(base_path / \"ward_temporal_test_data_eav.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b55810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e852bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def process_temporal(in_static_data, in_temporal_data):\n",
    "    all_temporal_data = []\n",
    "    horizons = []\n",
    "    \n",
    "    for uid in in_static_data[\"id\"].unique():\n",
    "        local_temporal_idx = in_temporal_data[\"id\"] == uid\n",
    "        local_temporal = in_temporal_data[local_temporal_idx]\n",
    "        columns = sorted(local_temporal[\"variable\"].unique())\n",
    "        times = sorted(local_temporal[\"time\"].unique())\n",
    "\n",
    "        temporal_data = pd.DataFrame([], columns = columns)\n",
    "\n",
    "\n",
    "        for horizon in times:\n",
    "            local_temporal_horizon_idx = local_temporal[\"time\"] == horizon\n",
    "            local_temporal_horizon = local_temporal[local_temporal_horizon_idx]\n",
    "\n",
    "            horizon_data = pd.DataFrame(-1 * np.ones((1, len(columns))), columns = columns)\n",
    "\n",
    "            proc = local_temporal_horizon[[\"variable\", \"value\"]]\n",
    "            proc.index = local_temporal_horizon[\"variable\"]\n",
    "            proc = proc.drop(columns = [\"variable\"])\n",
    "            proc = proc.T.reset_index(drop = True)\n",
    "            print(len(proc.columns), len(columns))\n",
    "            horizon_data[proc.columns] = proc\n",
    "\n",
    "            temporal_data = pd.concat([temporal_data, horizon_data], ignore_index = True)\n",
    "        temporal_data.index = times\n",
    "\n",
    "        for col in columns:\n",
    "            if col not in temporal_data:\n",
    "                temporal_data[col] = -1\n",
    "        horizons.append(temporal_data[\"time\"])\n",
    "        all_temporal_data.append(temporal_data[columns])\n",
    "        \n",
    "    assert len(all_temporal_data) == len(in_static_data)\n",
    "\n",
    "    return all_temporal_data, horizons\n",
    "\n",
    "def eav_to_wide(df):\n",
    "    \"\"\"Transform EAV format to WIDE format.\n",
    "    \n",
    "    Args:\n",
    "        - df: EAV format dataframe\n",
    "        \n",
    "    Returns:\n",
    "        - df_wide: WIDE format dataframe.    \n",
    "    \"\"\"\n",
    "    # Original data needs the following four column name in order.\n",
    "    col_names = list(df.columns)\n",
    "    assert col_names[0] == \"id\"\n",
    "    assert col_names[1] == \"time\"\n",
    "    assert col_names[2] == \"variable\"\n",
    "    assert col_names[3] == \"value\"\n",
    "\n",
    "    # Convert EAV format to WIDE format\n",
    "    df_wide = pd.pivot_table(df, index=[\"id\", \"time\"], columns=\"variable\", values=\"value\").reset_index(level=[0, 1])\n",
    "    return df_wide\n",
    "\n",
    "\n",
    "train_temporal_wide = eav_to_wide(train_temporal)\n",
    "test_temporal_wide = eav_to_wide(test_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071d22b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>Best Motor Response</th>\n",
       "      <th>Best Verbal Response</th>\n",
       "      <th>CHLORIDE</th>\n",
       "      <th>CREATINEINE</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Eye Opening</th>\n",
       "      <th>GLUCLOSE</th>\n",
       "      <th>Glasgow Coma Scale Score</th>\n",
       "      <th>...</th>\n",
       "      <th>POTASSIUM</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>SBP</th>\n",
       "      <th>SODIUM</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>TOTAL CO2</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>UREA NITROGEN</th>\n",
       "      <th>WHITE BLOOD CELL COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>107.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>174.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.5</td>\n",
       "      <td>17.00</td>\n",
       "      <td>156.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>169.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>162.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>239.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>241.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>247.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.5</td>\n",
       "      <td>16.75</td>\n",
       "      <td>113.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>248.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  id   time  Best Motor Response  Best Verbal Response  CHLORIDE  \\\n",
       "0          1    0.0                  5.0                   5.0      99.0   \n",
       "1          1    2.0                  5.0                   5.0       NaN   \n",
       "2          1    3.0                  5.0                   5.0       NaN   \n",
       "3          1    4.0                  5.0                   5.0       NaN   \n",
       "4          1    6.0                  5.0                   5.0       NaN   \n",
       "..        ..    ...                  ...                   ...       ...   \n",
       "75         1  239.0                  6.0                   5.0       NaN   \n",
       "76         1  240.0                  NaN                   NaN      97.0   \n",
       "77         1  241.0                  6.0                   5.0       NaN   \n",
       "78         1  247.0                  6.0                   5.0       NaN   \n",
       "79         1  248.0                  6.0                   5.0       NaN   \n",
       "\n",
       "variable  CREATINEINE     DBP  Eye Opening  GLUCLOSE  \\\n",
       "0                 0.6  107.00          3.0     133.0   \n",
       "1                 NaN   96.50          3.0       NaN   \n",
       "2                 NaN  104.00          3.0       NaN   \n",
       "3                 NaN  115.00          3.0       NaN   \n",
       "4                 NaN  102.00          3.0       NaN   \n",
       "..                ...     ...          ...       ...   \n",
       "75                NaN   65.00          4.0       NaN   \n",
       "76                0.5     NaN          NaN     103.0   \n",
       "77                NaN   80.00          4.0       NaN   \n",
       "78                NaN   68.25          4.0       NaN   \n",
       "79                NaN   64.00          4.0       NaN   \n",
       "\n",
       "variable  Glasgow Coma Scale Score  ...  POTASSIUM  Pulse  Respiratory Rate  \\\n",
       "0                             13.0  ...        3.8   78.0             12.00   \n",
       "1                             13.0  ...        NaN   85.5             17.00   \n",
       "2                             13.0  ...        NaN   79.0             18.00   \n",
       "3                             13.0  ...        NaN   73.0             18.00   \n",
       "4                             13.0  ...        NaN   76.0             18.00   \n",
       "..                             ...  ...        ...    ...               ...   \n",
       "75                            15.0  ...        NaN   89.0             16.00   \n",
       "76                             NaN  ...        3.7    NaN               NaN   \n",
       "77                            15.0  ...        NaN   89.0             17.00   \n",
       "78                            15.0  ...        NaN   88.5             16.75   \n",
       "79                            15.0  ...        NaN   84.0             16.00   \n",
       "\n",
       "variable    SBP  SODIUM    SpO2  TOTAL CO2  Temperature  UREA NITROGEN  \\\n",
       "0         174.0   136.0  100.00       21.0         98.6            8.0   \n",
       "1         156.5     NaN  100.00        NaN         98.1            NaN   \n",
       "2         169.0     NaN  100.00        NaN         98.1            NaN   \n",
       "3         177.0     NaN  100.00        NaN         98.1            NaN   \n",
       "4         162.0     NaN  100.00        NaN         98.1            NaN   \n",
       "..          ...     ...     ...        ...          ...            ...   \n",
       "75        110.0     NaN   99.00        NaN         99.5            NaN   \n",
       "76          NaN   135.0     NaN       24.5          NaN            6.0   \n",
       "77        127.0     NaN   99.00        NaN         97.5            NaN   \n",
       "78        113.5     NaN   97.25        NaN         97.7            NaN   \n",
       "79        109.0     NaN   97.00        NaN         97.7            NaN   \n",
       "\n",
       "variable  WHITE BLOOD CELL COUNT  \n",
       "0                          19.75  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "..                           ...  \n",
       "75                           NaN  \n",
       "76                         14.99  \n",
       "77                           NaN  \n",
       "78                           NaN  \n",
       "79                           NaN  \n",
       "\n",
       "[80 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_temporal_wide[train_temporal_wide[\"id\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea7f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_temporal(temporal_wide):\n",
    "    temporal = []\n",
    "    horizons = []\n",
    "    for k, v in temporal_wide.groupby(\"id\"):\n",
    "        h = v[\"time\"].values.tolist()\n",
    "        local_data = v.drop(columns = [\"id\", \"time\"])\n",
    "        local_data.index = h\n",
    "        local_data = local_data.dropna()\n",
    "        \n",
    "        horizons.append(local_data.index)\n",
    "        temporal.append(local_data)\n",
    "    return temporal, horizons\n",
    "\n",
    "train_temporal, train_horizons = prepare_temporal(train_temporal_wide)\n",
    "test_temporal, test_horizons = prepare_temporal(test_temporal_wide)\n",
    "\n",
    "train_outcome = train_static[\"icu_admission\"]\n",
    "test_outcome = test_static[\"icu_admission\"]\n",
    "train_static = train_static.drop(columns = [\"id\", \"icu_admission\"]).fillna(0)\n",
    "test_static = test_static.drop(columns = [\"id\", \"icu_admission\"]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a5e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_temporal) == len(train_static)\n",
    "assert len(test_temporal) == len(test_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251cf72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from synthcity.plugins.core.dataloader import (\n",
    "     TimeSeriesDataLoader,\n",
    ")\n",
    "\n",
    "dataloader_train = TimeSeriesDataLoader(\n",
    "    temporal_data=train_temporal,\n",
    "    temporal_horizons=train_horizons,\n",
    "    static_data=train_static,\n",
    "    outcome = train_outcome.to_frame(),\n",
    ")\n",
    "\n",
    "\n",
    "dataloader_test = TimeSeriesDataLoader(\n",
    "    temporal_data=test_temporal,\n",
    "    temporal_horizons=test_horizons,\n",
    "    static_data=test_static,\n",
    "    outcome = test_outcome.to_frame(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ec250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a700a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_static_eval, train_temporal_eval, train_horizons_eval, train_outcome_eval = dataloader_train.unpack(as_numpy = True, pad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7a62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_static_eval, test_temporal_eval, test_horizons_eval, test_outcome_eval = dataloader_test.unpack(as_numpy = True, pad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c3743b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>Best Motor Response</th>\n",
       "      <th>Best Verbal Response</th>\n",
       "      <th>CHLORIDE</th>\n",
       "      <th>CREATINEINE</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Eye Opening</th>\n",
       "      <th>GLUCLOSE</th>\n",
       "      <th>Glasgow Coma Scale Score</th>\n",
       "      <th>HEMOGLOBIN</th>\n",
       "      <th>O2 Device: Aerosol mask</th>\n",
       "      <th>...</th>\n",
       "      <th>POTASSIUM</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>SBP</th>\n",
       "      <th>SODIUM</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>TOTAL CO2</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>UREA NITROGEN</th>\n",
       "      <th>WHITE BLOOD CELL COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>107.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>98.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>266.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>101.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>101.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>129.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>91.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  Best Motor Response  Best Verbal Response  CHLORIDE  CREATINEINE  \\\n",
       "0.0                       5.0                   5.0      99.0          0.6   \n",
       "48.0                      6.0                   5.0     108.0          0.4   \n",
       "83.0                      6.0                   5.0     102.0          0.4   \n",
       "96.0                      6.0                   5.0      96.0          0.4   \n",
       "118.0                     6.0                   5.0      97.0          0.5   \n",
       "\n",
       "variable    DBP  Eye Opening  GLUCLOSE  Glasgow Coma Scale Score  HEMOGLOBIN  \\\n",
       "0.0       107.0          3.0     133.0                      13.0        13.5   \n",
       "48.0       90.0          4.0     105.0                      15.0        13.6   \n",
       "83.0       72.0          4.0     266.5                      15.0        11.3   \n",
       "96.0       73.0          4.0     428.0                      15.0        12.3   \n",
       "118.0      81.0          4.0     110.0                      15.0        11.9   \n",
       "\n",
       "variable  O2 Device: Aerosol mask  ...  POTASSIUM  Pulse  Respiratory Rate  \\\n",
       "0.0                           0.0  ...        3.8   78.0              12.0   \n",
       "48.0                          0.0  ...        3.6   85.0              20.0   \n",
       "83.0                          0.0  ...        3.3  101.0              18.0   \n",
       "96.0                          0.0  ...        3.0   96.5              20.0   \n",
       "118.0                         0.0  ...        3.8   91.5              19.0   \n",
       "\n",
       "variable    SBP  SODIUM   SpO2  TOTAL CO2  Temperature  UREA NITROGEN  \\\n",
       "0.0       174.0   136.0  100.0       21.0         98.6            8.0   \n",
       "48.0      146.0   138.0   95.0       19.0         98.9            9.0   \n",
       "83.0      138.0   132.0   95.0       19.0        101.1            7.5   \n",
       "96.0      129.5   126.0   95.5       19.0         99.4            6.0   \n",
       "118.0     138.0   135.0   96.0       22.0         98.7            6.0   \n",
       "\n",
       "variable  WHITE BLOOD CELL COUNT  \n",
       "0.0                        19.75  \n",
       "48.0                       18.43  \n",
       "83.0                       13.55  \n",
       "96.0                       16.31  \n",
       "118.0                      18.40  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_temporal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a090a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a5603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a24eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from synthcity.plugins.core.models.survival_analysis.metrics import (\n",
    "     evaluate_brier_score,\n",
    "     evaluate_c_index,\n",
    "     generate_score,\n",
    "     print_score,\n",
    " )\n",
    "import synthcity.logger as log\n",
    "import sys\n",
    "\n",
    "log.remove()\n",
    "log.add(sink=sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "def evaluate_ts_classification(\n",
    "     estimator: Any,\n",
    "     static: np.ndarray,\n",
    "     temporal: np.ndarray,\n",
    "     temporal_horizons: np.ndarray,\n",
    "     Y: np.ndarray,\n",
    "     n_folds: int = 3,\n",
    "     metrics: List[str] = [\"aucroc\"],\n",
    "     random_state: int = 0,\n",
    "     pretrained: bool = False,\n",
    "):\n",
    "    results = {\n",
    "        \"aucroc\": [],\n",
    "    }\n",
    " \n",
    "    static = np.asarray(static)\n",
    "    temporal = np.asarray(temporal, dtype=object)\n",
    "    temporal_horizons = np.asarray(temporal_horizons, dtype=object)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    def _get_metrics(\n",
    "        cv_idx: int,\n",
    "        static_train: np.ndarray,\n",
    "        static_test: np.ndarray,\n",
    "        temporal_train: np.ndarray,\n",
    "        temporal_test: np.ndarray,\n",
    "        temporal_horizons_train: np.ndarray,\n",
    "        temporal_horizons_test: np.ndarray,\n",
    "        Y_train: np.ndarray,\n",
    "        Y_test: np.ndarray,\n",
    "    ) -> tuple:\n",
    "        if pretrained:\n",
    "            model = estimator[cv_idx]\n",
    "        else:\n",
    "            model = copy.deepcopy(estimator)\n",
    "\n",
    "            model.fit(\n",
    "                static_train, temporal_train, temporal_horizons_train, Y_train\n",
    "            )\n",
    "        pred = model.predict(\n",
    "                static_test, temporal_test, temporal_horizons_test\n",
    "            )\n",
    " \n",
    "        return roc_auc_score(Y_test, pred)\n",
    "\n",
    "    if n_folds == 1:\n",
    "        cv_idx = 0\n",
    "        (\n",
    "            static_train,\n",
    "            static_test,\n",
    "            temporal_train,\n",
    "            temporal_test,\n",
    "            temporal_horizons_train,\n",
    "            temporal_horizons_test,\n",
    "            Y_train,\n",
    "            Y_test,\n",
    "        ) = train_test_split(\n",
    "            static, temporal, temporal_horizons, Y, random_state=random_state\n",
    "        )\n",
    " \n",
    "        aucroc = _get_metrics(\n",
    "            cv_idx,\n",
    "            static_train,\n",
    "            static_test,\n",
    "            temporal_train,\n",
    "            temporal_test,\n",
    "            temporal_horizons_train,\n",
    "            temporal_horizons_test,\n",
    "            Y_train,\n",
    "            Y_test,\n",
    "        )\n",
    "        results[\"aucroc\"] = [aucroc]\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    " \n",
    "        cv_idx = 0\n",
    "        for train_index, test_index in skf.split(temporal, Y):\n",
    "            static_train = static[train_index]\n",
    "            temporal_train = temporal[train_index]\n",
    "            temporal_horizons_train = temporal_horizons[train_index]\n",
    "            Y_train = Y[train_index]\n",
    " \n",
    "            static_test = static[test_index]\n",
    "            temporal_test = temporal[test_index]\n",
    "            temporal_horizons_test = temporal_horizons[test_index]\n",
    "            Y_test = Y[test_index]\n",
    " \n",
    " \n",
    "            aucroc = _get_metrics(\n",
    "                cv_idx,\n",
    "                static_train,\n",
    "                static_test,\n",
    "                temporal_train,\n",
    "                temporal_test,\n",
    "                temporal_horizons_train,\n",
    "                temporal_horizons_test,\n",
    "                Y_train,\n",
    "                Y_test,\n",
    "            )\n",
    "            results[\"aucroc\"].append(aucroc)\n",
    " \n",
    "            cv_idx += 1\n",
    " \n",
    "    output: dict = {\n",
    "        \"clf\": {},\n",
    "        \"str\": {},\n",
    "    }\n",
    " \n",
    "    for metric in metrics:\n",
    "        output[\"clf\"][metric] = generate_score(results[metric])\n",
    "        output[\"str\"][metric] = print_score(output[\"clf\"][metric])\n",
    " \n",
    "    return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d399fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from typing import Any, Callable, List, Optional, Tuple\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydantic import validate_arguments\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, sampler\n",
    "from tsai.models.gMLP import gMLP\n",
    "from tsai.models.InceptionTime import InceptionTime\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.models.MINIROCKET_Pytorch import MiniRocket\n",
    "from tsai.models.MINIROCKETPlus_Pytorch import MiniRocketPlus\n",
    "from tsai.models.mWDN import mWDNPlus\n",
    "from tsai.models.OmniScaleCNN import OmniScaleCNN\n",
    "from tsai.models.ResCNN import ResCNN\n",
    "from tsai.models.RNN_FCN import MLSTM_FCN\n",
    "from tsai.models.TCN import TCN\n",
    "from tsai.models.TransformerModel import TransformerModel\n",
    "from tsai.models.TSiTPlus import TSiTPlus\n",
    "from tsai.models.TST import TST\n",
    "from tsai.models.TSTPlus import TSTPlus\n",
    "from tsai.models.XceptionTime import XceptionTime\n",
    "from tsai.models.XCM import XCM\n",
    "\n",
    "# synthcity absolute\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins.core.models.mlp import MLP, MultiActivationHead, get_nonlin\n",
    "from synthcity.utils.constants import DEVICE\n",
    "from synthcity.utils.reproducibility import enable_reproducible_results\n",
    "\n",
    "modes = [\n",
    "    \"LSTM\",\n",
    "    \"GRU\",\n",
    "    \"RNN\",\n",
    "    \"MLSTM_FCN\",\n",
    "    \"TCN\",\n",
    "    \"InceptionTime\",\n",
    "    \"InceptionTimePlus\",\n",
    "    \"XceptionTime\",\n",
    "    \"ResCNN\",\n",
    "    \"OmniScaleCNN\",\n",
    "    \"TST\",\n",
    "    \"TSTPlus\",\n",
    "    \"XCM\",\n",
    "    \"gMLP\",\n",
    "    \"MiniRocket\",\n",
    "    \"MiniRocketPlus\",\n",
    "    \"TransformerModel\",\n",
    "    \"TSiTPlus\",\n",
    "    \"mWDNPlus\",\n",
    "]\n",
    "\n",
    "\n",
    "class TimeSeriesModel(nn.Module):\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def __init__(\n",
    "        self,\n",
    "        task_type: str,  # regression, classification\n",
    "        n_static_units_in: int,\n",
    "        n_temporal_units_in: int,\n",
    "        n_temporal_window: int,\n",
    "        output_shape: List[int],\n",
    "        n_static_units_hidden: int = 102,\n",
    "        n_static_layers_hidden: int = 2,\n",
    "        n_temporal_units_hidden: int = 102,\n",
    "        n_temporal_layers_hidden: int = 2,\n",
    "        n_iter: int = 500,\n",
    "        mode: str = \"RNN\",\n",
    "        n_iter_print: int = 10,\n",
    "        batch_size: int = 150,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 1e-3,\n",
    "        window_size: int = 1,\n",
    "        device: Any = DEVICE,\n",
    "        dataloader_sampler: Optional[sampler.Sampler] = None,\n",
    "        nonlin_out: Optional[List[Tuple[str, int]]] = None,\n",
    "        loss: Optional[Callable] = None,\n",
    "        dropout: float = 0,\n",
    "        nonlin: Optional[str] = \"relu\",\n",
    "        random_state: int = 0,\n",
    "        clipping_value: int = 1,\n",
    "        use_horizon_condition: bool = True,\n",
    "    ) -> None:\n",
    "        super(TimeSeriesModel, self).__init__()\n",
    "\n",
    "        enable_reproducible_results(random_state)\n",
    "\n",
    "        assert task_type in [\"classification\", \"regression\"]\n",
    "        assert mode in modes, f\"Unsupported mode {mode}. Available: {modes}\"\n",
    "        assert len(output_shape) > 0\n",
    "\n",
    "        self.task_type = task_type\n",
    "\n",
    "        if loss is not None:\n",
    "            self.loss = loss\n",
    "        elif task_type == \"regression\":\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif task_type == \"classification\":\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "        self.n_iter_print = n_iter_print\n",
    "        self.batch_size = batch_size\n",
    "        self.n_static_units_in = n_static_units_in\n",
    "        self.n_temporal_units_in = n_temporal_units_in\n",
    "        self.n_temporal_window = n_temporal_window\n",
    "        self.n_static_units_hidden = n_static_units_hidden\n",
    "        self.n_temporal_units_hidden = n_temporal_units_hidden\n",
    "        self.n_static_layers_hidden = n_static_layers_hidden\n",
    "        self.n_temporal_layers_hidden = n_temporal_layers_hidden\n",
    "        self.device = device\n",
    "        self.window_size = window_size\n",
    "        self.dataloader_sampler = dataloader_sampler\n",
    "        self.lr = lr\n",
    "        self.output_shape = output_shape\n",
    "        self.n_units_out = np.prod(self.output_shape)\n",
    "        self.clipping_value = clipping_value\n",
    "        self.use_horizon_condition = use_horizon_condition\n",
    "\n",
    "        self.temporal_layer = TimeSeriesLayer(\n",
    "            n_static_units_in=n_static_units_in,\n",
    "            n_temporal_units_in=n_temporal_units_in\n",
    "            + int(use_horizon_condition),  # measurements + horizon\n",
    "            n_temporal_window=n_temporal_window,\n",
    "            n_units_out=self.n_units_out,\n",
    "            n_static_units_hidden=n_static_units_hidden,\n",
    "            n_static_layers_hidden=n_static_layers_hidden,\n",
    "            n_temporal_units_hidden=n_temporal_units_hidden,\n",
    "            n_temporal_layers_hidden=n_temporal_layers_hidden,\n",
    "            mode=mode,\n",
    "            window_size=window_size,\n",
    "            device=device,\n",
    "            dropout=dropout,\n",
    "            nonlin=nonlin,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        self.out_activation: Optional[nn.Module] = None\n",
    "        self.n_act_out: Optional[int] = None\n",
    "\n",
    "        if nonlin_out is not None:\n",
    "            self.n_act_out = 0\n",
    "            activations = []\n",
    "            for nonlin, nonlin_len in nonlin_out:\n",
    "                self.n_act_out += nonlin_len\n",
    "                activations.append((get_nonlin(nonlin), nonlin_len))\n",
    "\n",
    "            if self.n_units_out % self.n_act_out != 0:\n",
    "                raise RuntimeError(\n",
    "                    f\"Shape mismatch for the output layer. Expected length {self.n_units_out}, but got {nonlin_out} with length {self.n_act_out}\"\n",
    "                )\n",
    "            self.out_activation = MultiActivationHead(activations, device=device)\n",
    "        elif self.task_type == \"classification\":\n",
    "            self.n_act_out = self.n_units_out\n",
    "            self.out_activation = MultiActivationHead(\n",
    "                [(nn.Softmax(dim=-1), self.n_units_out)], device=device\n",
    "            )\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "        )  # optimize all rnn parameters\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def forward(\n",
    "        self,\n",
    "        static_data: torch.Tensor,\n",
    "        temporal_data: torch.Tensor,\n",
    "        temporal_horizons: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "\n",
    "        assert torch.isnan(static_data).sum() == 0\n",
    "        assert torch.isnan(temporal_data).sum() == 0\n",
    "        assert torch.isnan(temporal_horizons).sum() == 0\n",
    "\n",
    "        if self.use_horizon_condition:\n",
    "            temporal_data_merged = torch.cat(\n",
    "                [temporal_data, temporal_horizons.unsqueeze(2)], dim=2\n",
    "            )\n",
    "        else:\n",
    "            temporal_data_merged = temporal_data\n",
    "\n",
    "        assert torch.isnan(temporal_data_merged).sum() == 0\n",
    "\n",
    "        pred = self.temporal_layer(static_data, temporal_data_merged)\n",
    "\n",
    "        if self.out_activation is not None:\n",
    "            pred = pred.reshape(-1, self.n_act_out)\n",
    "            pred = self.out_activation(pred)\n",
    "\n",
    "        pred = pred.reshape(-1, *self.output_shape)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def predict(\n",
    "        self,\n",
    "        static_data: np.ndarray,\n",
    "        temporal_data: np.ndarray,\n",
    "        temporal_horizons: np.ndarray,\n",
    "    ) -> np.ndarray:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            temporal_data_t = self._check_tensor(temporal_data).float()\n",
    "            temporal_horizons_t = self._check_tensor(temporal_horizons).float()\n",
    "            static_data_t = self._check_tensor(static_data).float()\n",
    "\n",
    "            yt = self(static_data_t, temporal_data_t, temporal_horizons_t)\n",
    "\n",
    "            if self.task_type == \"classification\":\n",
    "                return np.argmax(yt.cpu().numpy(), -1)\n",
    "            else:\n",
    "                return yt.cpu().numpy()\n",
    "\n",
    "    def score(\n",
    "        self,\n",
    "        static_data: np.ndarray,\n",
    "        temporal_data: np.ndarray,\n",
    "        temporal_horizons: np.ndarray,\n",
    "        outcome: np.ndarray,\n",
    "    ) -> float:\n",
    "        y_pred = self.predict(static_data, temporal_data, temporal_horizons)\n",
    "        if self.task_type == \"classification\":\n",
    "            return np.mean(y_pred == outcome)\n",
    "        else:\n",
    "            return np.mean(np.inner(outcome - y_pred, outcome - y_pred) / 2.0)\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def fit(\n",
    "        self,\n",
    "        static_data: np.ndarray,\n",
    "        temporal_data: np.ndarray,\n",
    "        temporal_horizons: np.ndarray,\n",
    "        outcome: np.ndarray,\n",
    "    ) -> Any:\n",
    "        temporal_data_t = self._check_tensor(temporal_data).float()\n",
    "        temporal_horizons_t = self._check_tensor(temporal_horizons).float()\n",
    "        static_data_t = self._check_tensor(static_data).float()\n",
    "        outcome_t = self._check_tensor(outcome).float()\n",
    "        if self.task_type == \"classification\":\n",
    "            outcome_t = outcome_t.long()\n",
    "\n",
    "        return self._train(\n",
    "            static_data_t, temporal_data_t, temporal_horizons_t, outcome_t\n",
    "        )\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def _train(\n",
    "        self,\n",
    "        static_data: Optional[torch.Tensor],\n",
    "        temporal_data: torch.Tensor,\n",
    "        temporal_horizons: torch.Tensor,\n",
    "        outcome: torch.Tensor,\n",
    "    ) -> Any:\n",
    "        loader = self.dataloader(static_data, temporal_data, temporal_horizons, outcome)\n",
    "        # training and testing\n",
    "        for it in range(self.n_iter):\n",
    "            loss = self._train_epoch(loader)\n",
    "            if it % self.n_iter_print == 0:\n",
    "                log.info(f\"Epoch:{it}| train loss: {loss}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _train_epoch(self, loader: DataLoader) -> float:\n",
    "        losses = []\n",
    "        for step, (static_mb, temporal_mb, horizons_mb, y_mb) in enumerate(loader):\n",
    "            self.optimizer.zero_grad()  # clear gradients for this training step\n",
    "\n",
    "            pred = self(static_mb, temporal_mb, horizons_mb)  # rnn output\n",
    "            loss = self.loss(pred, y_mb)\n",
    "\n",
    "            loss.backward()  # backpropagation, compute gradients\n",
    "            if self.clipping_value > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), self.clipping_value)\n",
    "            self.optimizer.step()  # apply gradients\n",
    "\n",
    "            losses.append(loss.detach().cpu())\n",
    "\n",
    "        return np.mean(losses)\n",
    "\n",
    "    def dataloader(\n",
    "        self,\n",
    "        static_data: torch.Tensor,\n",
    "        temporal_data: torch.Tensor,\n",
    "        temporal_horizons: torch.Tensor,\n",
    "        outcome: torch.Tensor,\n",
    "    ) -> DataLoader:\n",
    "        dataset = TensorDataset(static_data, temporal_data, temporal_horizons, outcome)\n",
    "\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=self.dataloader_sampler,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "    def _check_tensor(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if isinstance(X, torch.Tensor):\n",
    "            return X.to(self.device)\n",
    "        else:\n",
    "            return torch.from_numpy(np.asarray(X)).to(self.device)\n",
    "\n",
    "\n",
    "class TimeSeriesLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_static_units_in: int,\n",
    "        n_temporal_units_in: int,\n",
    "        n_temporal_window: int,\n",
    "        n_units_out: int,\n",
    "        n_static_units_hidden: int = 100,\n",
    "        n_static_layers_hidden: int = 2,\n",
    "        n_temporal_units_hidden: int = 100,\n",
    "        n_temporal_layers_hidden: int = 2,\n",
    "        mode: str = \"RNN\",\n",
    "        window_size: int = 1,\n",
    "        device: Any = DEVICE,\n",
    "        dropout: float = 0,\n",
    "        nonlin: Optional[str] = \"relu\",\n",
    "        random_state: int = 0,\n",
    "    ) -> None:\n",
    "        super(TimeSeriesLayer, self).__init__()\n",
    "        temporal_params = {\n",
    "            \"input_size\": n_temporal_units_in,\n",
    "            \"hidden_size\": n_temporal_units_hidden,\n",
    "            \"num_layers\": n_temporal_layers_hidden,\n",
    "            \"dropout\": 0 if n_temporal_layers_hidden == 1 else dropout,\n",
    "            \"batch_first\": True,\n",
    "        }\n",
    "        temporal_models = {\n",
    "            \"RNN\": nn.RNN,\n",
    "            \"LSTM\": nn.LSTM,\n",
    "            \"GRU\": nn.GRU,\n",
    "        }\n",
    "\n",
    "        if mode in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "            self.temporal_layer = temporal_models[mode](**temporal_params)\n",
    "        elif mode == \"MLSTM_FCN\":\n",
    "            self.temporal_layer = MLSTM_FCN(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                hidden_size=n_temporal_units_hidden,\n",
    "                rnn_layers=n_temporal_layers_hidden,\n",
    "                fc_dropout=dropout,\n",
    "                seq_len=n_temporal_window,\n",
    "                shuffle=False,\n",
    "            )\n",
    "        elif mode == \"TCN\":\n",
    "            self.temporal_layer = TCN(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                fc_dropout=dropout,\n",
    "            )\n",
    "        elif mode == \"InceptionTime\":\n",
    "            self.temporal_layer = InceptionTime(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                depth=n_temporal_layers_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "            )\n",
    "        elif mode == \"InceptionTimePlus\":\n",
    "            self.temporal_layer = InceptionTimePlus(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                depth=n_temporal_layers_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "            )\n",
    "        elif mode == \"XceptionTime\":\n",
    "            self.temporal_layer = XceptionTime(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "            )\n",
    "        elif mode == \"ResCNN\":\n",
    "            self.temporal_layer = ResCNN(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "            )\n",
    "        elif mode == \"OmniScaleCNN\":\n",
    "            self.temporal_layer = OmniScaleCNN(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=max(n_temporal_window, 10),\n",
    "            )\n",
    "        elif mode == \"TST\":\n",
    "            self.temporal_layer = TST(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                max_seq_len=n_temporal_window,\n",
    "                n_layers=n_temporal_layers_hidden,\n",
    "            )\n",
    "        elif mode == \"XCM\":\n",
    "            self.temporal_layer = XCM(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                fc_dropout=dropout,\n",
    "            )\n",
    "        elif mode == \"gMLP\":\n",
    "            self.temporal_layer = gMLP(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                depth=n_temporal_layers_hidden,\n",
    "            )\n",
    "        elif mode == \"MiniRocket\":\n",
    "            self.temporal_layer = MiniRocket(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                random_state=random_state,\n",
    "                fc_dropout=dropout,\n",
    "            )\n",
    "        elif mode == \"MiniRocketPlus\":\n",
    "            self.temporal_layer = MiniRocketPlus(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                fc_dropout=dropout,\n",
    "            )\n",
    "        elif mode == \"TransformerModel\":\n",
    "            self.temporal_layer = TransformerModel(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                dropout=dropout,\n",
    "                n_layers=n_temporal_layers_hidden,\n",
    "            )\n",
    "        elif mode == \"TSiTPlus\":\n",
    "            self.temporal_layer = TSiTPlus(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                depth=n_temporal_layers_hidden,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "        elif mode == \"TSTPlus\":\n",
    "            self.temporal_layer = TSTPlus(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "                n_layers=n_temporal_layers_hidden,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "        elif mode == \"mWDNPlus\":\n",
    "            self.temporal_layer = mWDNPlus(\n",
    "                c_in=n_temporal_units_in,\n",
    "                c_out=n_temporal_units_hidden,\n",
    "                seq_len=n_temporal_window,\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown TS mode {mode}\")\n",
    "\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "            self.out = WindowLinearLayer(\n",
    "                n_static_units_in=n_static_units_in,\n",
    "                n_temporal_units_in=n_temporal_units_hidden,\n",
    "                window_size=window_size,\n",
    "                n_units_out=n_units_out,\n",
    "                n_layers=n_static_layers_hidden,\n",
    "                dropout=dropout,\n",
    "                nonlin=nonlin,\n",
    "                device=device,\n",
    "            )\n",
    "        else:\n",
    "            self.out = MLP(\n",
    "                task_type=\"regression\",\n",
    "                n_units_in=n_static_units_in + n_temporal_units_hidden,\n",
    "                n_units_out=n_units_out,\n",
    "                n_layers_hidden=n_static_layers_hidden,\n",
    "                n_units_hidden=n_static_units_hidden,\n",
    "                dropout=dropout,\n",
    "                nonlin=nonlin,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "        self.temporal_layer.to(device)\n",
    "        self.out.to(device)\n",
    "\n",
    "    def forward(\n",
    "        self, static_data: torch.Tensor, temporal_data: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        if self.mode in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
    "            X_interm, _ = self.temporal_layer(temporal_data)\n",
    "\n",
    "            assert torch.isnan(X_interm).sum() == 0\n",
    "\n",
    "            return self.out(static_data, X_interm)\n",
    "        else:\n",
    "            X_interm = self.temporal_layer(torch.swapaxes(temporal_data, 1, 2))\n",
    "\n",
    "            assert torch.isnan(X_interm).sum() == 0\n",
    "\n",
    "            return self.out(torch.cat([static_data, X_interm], dim=1))\n",
    "\n",
    "\n",
    "class WindowLinearLayer(nn.Module):\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_static_units_in: int,\n",
    "        n_temporal_units_in: int,\n",
    "        window_size: int,\n",
    "        n_units_out: int,\n",
    "        n_units_hidden: int = 100,\n",
    "        n_layers: int = 1,\n",
    "        dropout: float = 0,\n",
    "        nonlin: Optional[str] = \"relu\",\n",
    "        device: Any = DEVICE,\n",
    "    ) -> None:\n",
    "        super(WindowLinearLayer, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.window_size = window_size\n",
    "        self.model = MLP(\n",
    "            task_type=\"regression\",\n",
    "            n_units_in=n_static_units_in + n_temporal_units_in * window_size,\n",
    "            n_units_out=n_units_out,\n",
    "            n_layers_hidden=n_layers,\n",
    "            n_units_hidden=n_units_hidden,\n",
    "            dropout=dropout,\n",
    "            nonlin=nonlin,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def forward(\n",
    "        self, static_data: torch.Tensor, temporal_data: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        assert len(static_data) == len(temporal_data)\n",
    "        batch_size, seq_len, n_feats = temporal_data.shape\n",
    "        temporal_batch = temporal_data[:, seq_len - self.window_size :, :].reshape(\n",
    "            batch_size, n_feats * self.window_size\n",
    "        )\n",
    "        batch = torch.cat([static_data, temporal_batch], axis=1)\n",
    "\n",
    "        return self.model(batch).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "418a698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-07-16T10:49:15.691159+0300][73514][INFO] Epoch:0| train loss: 0.6926623582839966\n",
      "[2022-07-16T10:49:20.919168+0300][73514][INFO] Epoch:10| train loss: 0.6813757419586182\n",
      "[2022-07-16T10:49:25.948066+0300][73514][INFO] Epoch:20| train loss: 0.6724405288696289\n",
      "[2022-07-16T10:49:30.973634+0300][73514][INFO] Epoch:30| train loss: 0.6722961664199829\n",
      "[2022-07-16T10:49:36.192089+0300][73514][INFO] Epoch:40| train loss: 0.669145405292511\n",
      "[2022-07-16T10:49:41.225527+0300][73514][INFO] Epoch:50| train loss: 0.6708655953407288\n",
      "[2022-07-16T10:49:46.458650+0300][73514][INFO] Epoch:60| train loss: 0.6705731749534607\n",
      "[2022-07-16T10:49:51.496984+0300][73514][INFO] Epoch:70| train loss: 0.6675920486450195\n",
      "[2022-07-16T10:49:56.535480+0300][73514][INFO] Epoch:80| train loss: 0.6683081984519958\n",
      "[2022-07-16T10:50:01.765552+0300][73514][INFO] Epoch:90| train loss: 0.6665168404579163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1629"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from synthcity.utils.samplers import ImbalancedDatasetSampler\n",
    "sampler = ImbalancedDatasetSampler(train_outcome_eval.squeeze().tolist())\n",
    "\n",
    "model = TimeSeriesModel(\n",
    "        task_type = \"classification\",  # regression, classification\n",
    "         n_static_units_in = train_static_eval.shape[-1],\n",
    "         n_temporal_units_in = train_temporal_eval.shape[-1],\n",
    "         n_temporal_window = train_temporal_eval.shape[1],\n",
    "         output_shape = [2],\n",
    "         dataloader_sampler = sampler,\n",
    "            n_iter = 100,\n",
    "    )\n",
    "\n",
    "model.fit(train_static_eval, train_temporal_eval, train_horizons_eval, train_outcome_eval.squeeze())\n",
    "\n",
    "model.predict(train_static_eval, train_temporal_eval, train_horizons_eval).sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1823c24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_static_eval, train_temporal_eval, train_horizons_eval).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42b9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_outcome_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab265d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea0c2f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthcity.plugins.core.models.ts_model import modes\n",
    "\n",
    "def eval_model(**kwargs):\n",
    "    n_folds = 3\n",
    "    model = TimeSeriesModel(\n",
    "        task_type = \"classification\",  # regression, classification\n",
    "         n_static_units_in = train_static.shape[-1],\n",
    "         n_temporal_units_in = train_temporal[0].shape[-1],\n",
    "         n_temporal_window = max([len(t) for t in train_temporal]),\n",
    "         output_shape = [2],\n",
    "        n_iter = 100,\n",
    "         **kwargs,\n",
    "    )\n",
    "\n",
    "    model.fit(train_static_eval, train_temporal_eval, train_horizons_eval, train_outcome_eval.squeeze())\n",
    "        \n",
    "    score = evaluate_ts_classification(\n",
    "        [model] * n_folds, \n",
    "        test_static, test_temporal, test_horizons, test_outcome_eval.squeeze(), \n",
    "        pretrained = True,\n",
    "        n_folds = n_folds\n",
    "    )\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d2d217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed RNN input.size(-1) must be equal to input_size. Expected 39, got 77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tabulate\n",
    "\n",
    "headers = [\"Model\", \"AUCROC\"]\n",
    "results = pd.DataFrame([], columns = headers)\n",
    "\n",
    "for mode in [\"RNN\"]:\n",
    "    try:\n",
    "        score = eval_model(mode = mode)[\"str\"]\n",
    "        \n",
    "        print(mode, score)\n",
    "    except BaseException as e:\n",
    "        print(\"failed\", mode, e)\n",
    "        continue\n",
    "    local_results = pd.DataFrame([[f\"TimeSeriesModel[{mode}]\", score[\"aucroc\"]]], columns = headers)\n",
    "    results = pd.concat([results, local_results], ignore_index = True)\n",
    "    \n",
    "    break\n",
    "    \n",
    "tabulate.tabulate(results, tablefmt='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7eda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outcome_eval.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469e2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
