{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e2d93c",
   "metadata": {},
   "source": [
    "# Tutorial 5: Generating data using Differential Privacy guarantees\n",
    "\n",
    "`synthcity` includes several privacy-focused generators. One class of privacy models is for differential privacy.\n",
    "\n",
    "The central idea behind `differential privacy` is to add random noise to the data in a way that preserves the overall statistical properties of the dataset, but makes it impossible to determine the presence or absence of any individual data point within the dataset. This is achieved by bounding the amount of information that any single query can reveal about an individual data point.\n",
    "\n",
    "One key element in DP is __epsilon (ε)__, a measure of the privacy loss of a given algorithm or mechanism. Specifically, it is a way to quantify the maximum amount by which the probability of any outcome (or set of outcomes) can change due to the inclusion or exclusion of a single individual's data.\n",
    "\n",
    "For example, suppose a given query to a differentially private algorithm has a privacy loss of ε=1. In that case, that means that the probability of any outcome (or set of outcomes) can change by, at most, a factor of e^1=2.718 (about 2.718 times) due to the inclusion or exclusion of a single individual's data. The lower the value of `ε`, the stronger the privacy guarantees provided by the algorithm or mechanism.\n",
    "\n",
    "One common way to achieve differential privacy is through the use of randomization. A differentially private algorithm will add noise to the output of a query in order to make it difficult to determine whether any particular individual's data was used in the computation. The amount of noise added is typically determined by the value of ε, with a lower value of ε resulting in more noise being added and stronger privacy guarantees.\n",
    "\n",
    "It is important to note that ε is not the only parameter that is used to measure privacy loss in differential privacy. Another commonly used parameter is __delta (δ)__, which represents the probability that the privacy loss of an algorithm or mechanism exceeds a certain threshold (often ε). Together, ε and δ can be used to specify the privacy guarantees of a differentially private algorithm or mechanism more precisely.\n",
    "\n",
    "\n",
    "`synthcity` includes the following models with DP-focus:\n",
    " - `AdsGAN` - A GAN with an identifiability penalty\n",
    " - `PATEGAN` - A GAN which uses the Private Aggregation of Teacher Ensembles (PATE) framework to tightly bound the influence of any individual sample on the model.\n",
    " - `PrivBayes` - uses a Bayesian network to iteratively learn a set of low-dimensional conditional probabilities from noisy marginals.\n",
    " - `DPGAN` - A GAN which uses the DP-SGD optimizer for training the discriminator.\n",
    " \n",
    " PATEGAN, PrivBayes, DPGAN have the `epsilon` parameter, which can be customized.\n",
    " AdsGAN takes a different approach, and the privacy level there can be controlled by the `lambda_identifiability_penalty` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install synthcity\n",
    "!pip uninstall -y torchaudio torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e0157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# third party\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# synthcity absolute\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "X[\"target\"] = y\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51076cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: preprocessing data with OneHotEncoder or StandardScaler is not needed or recommended. Synthcity handles feature encoding and standardization internally.\n",
    "loader = GenericDataLoader(\n",
    "    X,\n",
    "    target_column=\"target\",\n",
    "    sensitive_columns=[\"sex\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571da38",
   "metadata": {},
   "source": [
    "## List privacy plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de13c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plugins(categories=[\"privacy\"]).list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f2fe6",
   "metadata": {},
   "source": [
    "## Load and train a generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ed0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "syn_model = Plugins().get(\"dpgan\")\n",
    "\n",
    "syn_model.fit(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e1eeb",
   "metadata": {},
   "source": [
    "## Generate new data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model.generate(count=10).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5f782",
   "metadata": {},
   "source": [
    "## Benchmarking metrics\n",
    "\n",
    "| **Metric**                                         | **Description**                                                                                                            |\n",
    "|----------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------|\n",
    "| sanity.data\\_mismatch.score                        | Data types mismatch between the real//synthetic features                                                                   |\n",
    "| sanity.common\\_rows\\_proportion.score              | Real data copy-paste in the synthetic data                                                                                 |\n",
    "| sanity.nearest\\_syn\\_neighbor\\_distance.mean       | Computes the \\textless{}reduction\\textgreater{}(distance) from the real data to the closest neighbor in the synthetic data |\n",
    "| sanity.close\\_values\\_probability.score            | the probability of close values between the real and synthetic data.                                                       |\n",
    "| sanity.distant\\_values\\_probability.score          | the probability of distant values between the real and synthetic data.                                                     |\n",
    "| stats.jensenshannon\\_dist.marginal                 | the average Jensen-Shannon distance                                                                                        |\n",
    "| stats.chi\\_squared\\_test.marginal                  | the one-way chi-square test.                                                                                               |\n",
    "| stats.feature\\_corr.joint                          | the correlation/strength-of-association of features in data-set with both categorical and continuous features              |\n",
    "| stats.inv\\_kl\\_divergence.marginal                 | the average inverse of the Kullback–Leibler Divergence metric.                                                             |\n",
    "| stats.ks\\_test.marginal                            | the Kolmogorov-Smirnov test for goodness of fit.                                                                           |\n",
    "| stats.max\\_mean\\_discrepancy.joint                 | Empirical maximum mean discrepancy. The lower the result the more evidence that distributions are the same.                |\n",
    "| stats.prdc.precision                               | precision between the two manifolds                                                                                        |\n",
    "| stats.prdc.recall                                  | recall between the two manifolds                                                                                           |\n",
    "| stats.prdc.density                                 | density between the two manifolds                                                                                          |\n",
    "| stats.prdc.coverage                                | coverage between the two manifolds                                                                                         |\n",
    "| stats.alpha\\_precision.delta\\_precision\\_alpha\\_OC | Delta precision                                                                                                            |\n",
    "| stats.alpha\\_precision.delta\\_coverage\\_beta\\_OC   | Delta coverage                                                                                                             |\n",
    "| stats.alpha\\_precision.authenticity\\_OC            | Authetnticity                                                                                                              |\n",
    "| performance.linear\\_model.gt.aucroc              | Train on real, test on the test real data using LogisticRegression: AUCROC                                                             |\n",
    "| performance.linear\\_model.syn\\_id.aucroc         | Train on synthetic, test on the train real data using LogisticRegression: AUCROC                                                       |\n",
    "| performance.linear\\_model.syn\\_ood.aucroc        | Train on synthetic, test on the test real data using LogisticRegression: AUCROC                                                        |\n",
    "| performance.mlp.gt.aucroc                        | Train on real, test on the test real data using NN: AUCROC                                                                |\n",
    "| performance.mlp.syn\\_id.aucroc                    | Train on synthetic, test on the train real data using NN: AUCROC                                                          |\n",
    "| performance.mlp.syn\\_ood.aucroc                   | Train on synthetic, test on the test real data using NN: AUCROC                                                           |\n",
    "| performance.xgb.gt.aucroc                         | Train on real, test on the test real data using XGB: AUCROC                                                               |\n",
    "| performance.xgb.syn\\_id.aucroc                    | Train on synthetic, test on the train real data using XGB: AUCROC                                                         |\n",
    "| performance.xgb.syn\\_ood.aucroc                   | Train on synthetic, test on the test real data using XGB: AUCROC                                                          |\n",
    "| performance.feat\\_rank\\_distance.corr              | Correlation for the rank distances between the feature importance on real and synthetic data                               |\n",
    "| performance.feat\\_rank\\_distance.pvalue            | p-vale for the rank distances between the feature importance on real and synthetic data                                    |\n",
    "| detection.detection\\_xgb.mean                      | The average AUCROC score for detecting synthetic data using an XGBoost.                                                    |\n",
    "| detection.detection\\_mlp.mean                      | The average AUCROC score for detecting synthetic data using a NN.                                                          |\n",
    "| detection.detection\\_gmm.mean                      | The average AUCROC score for detecting synthetic data using a GMM.                                                         |\n",
    "| privacy.delta-presence.score                       | the maximum re-identification probability on the real dataset from the synthetic dataset.                                  |\n",
    "| privacy.k-anonymization.gt                         | the k-anon for the real data                                                                                               |\n",
    "| privacy.k-anonymization.syn                        | the k-anon for the synthetic data                                                                                          |\n",
    "| privacy.k-map.score                                | the minimum value k that satisfies the k-map rule.                                                                         |\n",
    "| privacy.distinct l-diversity.gt                    | the l-diversity for the real data                                                                                          |\n",
    "| privacy.distinct l-diversity.syn                   | the l-diversity for the synthetic data                                                                                     |\n",
    "| privacy.identifiability\\_score.score               | the re-identification score on the real dataset from the synthetic dataset.                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db52b9",
   "metadata": {},
   "source": [
    "## Benchmark the quality of DPGAN for various epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda7d3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.benchmark import Benchmarks\n",
    "\n",
    "score = Benchmarks.evaluate(\n",
    "    [(f\"test_eps_{eps}\", \"dpgan\", {\"epsilon\": eps}) for eps in [0.1, 1, 10]],\n",
    "    loader,\n",
    "    synthetic_size=1000,\n",
    "    repeats=2,\n",
    "    synthetic_reuse_if_exists=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a9004",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Benchmarks.print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706cd6e0",
   "metadata": {},
   "source": [
    "## Benchmark the quality of DP-models for epsilon=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c71be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.benchmark import Benchmarks\n",
    "\n",
    "score = Benchmarks.evaluate(\n",
    "    [\n",
    "        (f\"test_{model}\", model, {\"epsilon\": 0.1})\n",
    "        for model in [\"pategan\", \"dpgan\"]\n",
    "    ],\n",
    "    loader,\n",
    "    synthetic_size=1000,\n",
    "    repeats=2,\n",
    "    synthetic_reuse_if_exists=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Benchmarks.print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bdfe8b",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement towards Machine learning and AI for medicine, you can do so in the following ways!\n",
    "\n",
    "### Star [Synthcity](https://github.com/vanderschaarlab/synthcity) on GitHub\n",
    "\n",
    "- The easiest way to help our community is just by starring the Repos! This helps raise awareness of the tools we're building.\n",
    "\n",
    "\n",
    "### Checkout other projects from vanderschaarlab\n",
    "- [HyperImpute](https://github.com/vanderschaarlab/hyperimpute)\n",
    "- [AutoPrognosis](https://github.com/vanderschaarlab/autoprognosis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
